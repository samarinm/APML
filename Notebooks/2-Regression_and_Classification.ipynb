{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb16d01-345b-4468-b011-ca7f2b64a894",
   "metadata": {},
   "source": [
    "# 2. Regression and Classification\n",
    "\n",
    "Regression and classficiation are two fundamental tasks of supervised Machine Learning where labels\n",
    "allows us to guide the learning. This notebook reviews more standard approaches to regression and classification.\n",
    "\n",
    "We provide the fundamental ideas behind\n",
    "\n",
    "* linear regression and ridge regression\n",
    "* logistic regression for classification\n",
    "* decision trees and Random Forests\n",
    "\n",
    "and apply these techniques to simulated data and a dataset example (wine quality assessment).\n",
    "\n",
    "Keywords: ```OLS```, ```MSE```, ```Overfittng```, ```Regularisation```, ```np.linalg.inv```, ```sklearn.linear_model.LinearRegression```, ```sklearn.linear_model.Ridge```, ```sklearn.tree.DecisionTreeClassifier```, ```sklearn.linear_model.LogisticRegression```, ```sklearn.ensemble.RandomForestClassifier```, ```sklearn.model_selection.train_test_split```\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf62adf-14ed-485b-bf72-2e593373fc13",
   "metadata": {},
   "source": [
    "#### We start by fixing a random seed\n",
    "which controls the generation of (pseudo) random number sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b810c4-f086-431c-bdc0-2e0cd4017ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae7437-d3ce-446e-a01d-9b2305ab9e2e",
   "metadata": {},
   "source": [
    "#### Note \n",
    "\n",
    "that this enables reproducibility of our results even in the presence of \"randomness\".\n",
    "For example, the first three runs of the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ca7838-717f-4010-8c4b-6a486d945b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4809319 , 0.39211752, 0.34317802, 0.72904971])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random(size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e0fa3-0d27-49d7-9a07-ebd114321483",
   "metadata": {},
   "source": [
    "will always produce\n",
    "\n",
    "1. ```array([0.69646919, 0.28613933, 0.22685145, 0.55131477])```\n",
    "\n",
    "2. ```array([0.71946897, 0.42310646, 0.9807642 , 0.68482974])```\n",
    "\n",
    "3. ```array([0.4809319 , 0.39211752, 0.34317802, 0.72904971])```\n",
    "\n",
    "***\n",
    "\n",
    "## Standard Linear Regression and Ordinary Least Squares\n",
    "\n",
    "We assume a linear relationship between true **response** $Y_\\text{groundtruth} = Xw$ and **predictors / covariates** $X$. \n",
    "However, usually **our observation is not perfect**, i.e. there is some noise additional $\\epsilon$. \n",
    "\n",
    "A simple linear regression model is then\n",
    "\n",
    "\\begin{equation}\n",
    "    Y = Xw + \\epsilon.\n",
    "\\end{equation}\n",
    "\n",
    "Let us simulate $N=10$ datapoints with Gaussian noise $\\epsilon \\sim \\mathcal{N}(\\mu=0,\\sigma=20)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51649dfc-9b39-4931-9bcb-466056165397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.34257268]\n",
      " [14.30696675]\n",
      " [19.60587591]\n",
      " [21.15532301]\n",
      " [24.04659507]\n",
      " [27.56573845]\n",
      " [34.24148693]\n",
      " [34.82345928]\n",
      " [35.97344849]\n",
      " [49.03820992]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "num_datapoints = 10\n",
    "\n",
    "X = np.random.random(size=num_datapoints)*50\n",
    "X = np.sort(X).reshape(-1,1)\n",
    "\n",
    "print(X)\n",
    "\n",
    "w_groundtruth = 10\n",
    "Y_groundtruth = w_groundtruth*X\n",
    "\n",
    "epsilon_noise = np.random.normal(loc=0, scale=20.0, size=(num_datapoints,1))\n",
    "\n",
    "Y = Y_groundtruth + epsilon_noise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa6166-8649-439d-85b6-3dfccc0ae334",
   "metadata": {},
   "source": [
    "A typical objective function is given by the **mean squared error** (MSE) loss\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{Loss}(w) = \\frac{1}{2N} \\lVert \\epsilon \\rVert_2^2 = \\frac{1}{2N} \\lVert Y - Xw \\rVert_2^2 = \\frac{1}{2N} \\sum_{n=1}^{N} \\big( y_n -  x_n \\cdot w \\big)^2.\n",
    "\\end{equation}\n",
    "\n",
    "Under certain conditions, the solution to this equation will provide the **best linear (unbiased) estimator** for $w$! We identify the **minimum** through\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla  \\text{Loss}(w) = X^\\top Y - X^\\top X w \\equiv 0,\n",
    "\\end{equation}\n",
    "\n",
    "which provides the **ordinary least squares** (OLS) solution\n",
    "\n",
    "\\begin{equation}\n",
    "    w_\\text{OLS} = \\left( X^\\top X \\right)^{-1}X^\\top Y.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b5c9bc-f14b-490e-a1ab-ea637fb6009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution is given by w_OLS = 10.375338325958648.\n"
     ]
    }
   ],
   "source": [
    "XT = np.transpose(X)\n",
    "XTX_inverse = np.linalg.inv(XT @ X)\n",
    "\n",
    "w_OLS = XTX_inverse @ XT @ Y\n",
    "\n",
    "print(f\"The solution is given by w_OLS = {w_OLS.squeeze()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98059a17-f7e6-483d-808d-84b9fd7f121d",
   "metadata": {},
   "source": [
    "#### Note\n",
    "* Operator ```@``` provides the matrix multiplication of two numpy array (similar to ```np.matmul```)\n",
    "* Function ```numpy.array.squeeze()``` removes all dimensions of size ```1``` from a NumPy array, i.e.\n",
    "```python\n",
    "In: print(w_OLS.shape) \n",
    "Out: (1, 1)\n",
    "\n",
    "In: print(w_OLS)\n",
    "Out: [[10.04673211]]\n",
    "\n",
    "In: print(w_OLS.squeeze())\n",
    "Out: 10.046732109803889\n",
    "```\n",
    "\n",
    "Let's provide some predictions $Y_\\text{OLS}$ based on this solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96dfdba-38cd-4022-899c-e409d3adf4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_OLS = w_OLS * X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e3d86e-95b7-47ce-90bf-d9cab351821e",
   "metadata": {},
   "source": [
    "With this, we can calculate the **coefficient of determination** $R^2$ ([Wikipedia](https://en.wikipedia.org/wiki/Coefficient_of_determination)) through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f43c5a0-ae97-410d-a58c-b929969047fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965593882960831\n"
     ]
    }
   ],
   "source": [
    "Rsquared = 1 - np.sum((Y - Y_OLS)**2) / np.sum((Y - np.mean(Y))**2)\n",
    "print(Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0446ee-0178-434e-b59e-b0d72cb42ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, Y, color='red', label='Observations (with noise)')\n",
    "plt.plot(X, Y_groundtruth, color='red', linestyle='dashed', label=f'Groundtruth')\n",
    "plt.plot(X, Y_OLS, marker='x', color='blue', label=f'Fit with $R^2={Rsquared:.2f}$')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297f46e-eb58-47bc-b1ff-335b03559e62",
   "metadata": {},
   "source": [
    "What happens if you have more \"flexible models\" at your disposal? In the following, we try to fit our observed \n",
    "responses $Y$ with a polynomial model of the form \n",
    "\n",
    "\\begin{align}\n",
    "    Y &= X_\\text{poly}w + \\epsilon \\\\ \n",
    "    &= x \\cdot w_1 + x^2 \\cdot w_2 + x^3 \\cdot w_3 + ... + x^7 \\cdot w_7 + x^8 \\cdot w_8 + \\epsilon\n",
    "\\end{align}\n",
    "\n",
    "and create a hundred test datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd02ac6-3528-480e-bdc2-455ee0a254b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = np.hstack((X, X ** 2, X ** 3, X ** 4, X ** 5, X ** 6, X ** 7, X ** 8))\n",
    "print(X_poly.shape)\n",
    "\n",
    "X_test = np.linspace(10,50,100).reshape(-1, 1)\n",
    "X_test = np.hstack((X_test, X_test ** 2, X_test ** 3, X_test ** 4, X_test ** 5, X_test ** 6, X_test ** 7, X_test ** 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7aacf3-465f-42e7-b122-e49758a0caf4",
   "metadata": {},
   "source": [
    "Let's see the OLS solution for that case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f26363-330c-4643-9039-7afa875fd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = np.transpose(X_poly)\n",
    "XTX_inverse = np.linalg.inv(XT @ X_poly)\n",
    "\n",
    "w_OLS = XTX_inverse @ XT @ Y\n",
    "\n",
    "print(f\"Solution w_OLS = {w_OLS.squeeze()}\")\n",
    "\n",
    "Y_OLS = X_poly @ w_OLS\n",
    "Y_OLS_test = X_test @ w_OLS\n",
    "\n",
    "Rsquared = 1 - np.sum((Y - Y_OLS)**2) / np.sum((Y - np.mean(Y))**2)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,4))\n",
    "\n",
    "axs[0].scatter(X, Y, marker='o', color='red', label='Observations (with noise)')\n",
    "axs[0].plot(X, Y_groundtruth, color='red', linestyle='dashed', label=f'Groundtruth')\n",
    "axs[0].scatter(X, Y_OLS, color='blue', marker='X', label=f'Train; fit with $R^2={Rsquared:.2f}$')\n",
    "\n",
    "axs[1].scatter(X, Y, marker='o', color='red', label='Observations (with noise)')\n",
    "axs[1].plot(X, Y_groundtruth, color='red', linestyle='dashed', label=f'Groundtruth')\n",
    "axs[1].plot(X_test[:,0], Y_OLS_test, color='blue', label=f'Test')\n",
    "\n",
    "axs[0].set_xlabel('X')\n",
    "axs[0].set_ylabel('Y')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_xlabel('X')\n",
    "axs[1].set_ylabel('Y')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e8708-75b8-42a0-8d9d-f36a70b11a72",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Ridge Regression\n",
    "\n",
    "Ridge regression adds an additional assumption on (the distribution of) weights $w$. We rewrite the loss as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{Loss} (w) = \\frac{1}{2N} \\lVert Y - Xw \\rVert_2^2 {\\color{red}{+ \\frac{1}{2} \\lambda' \\lVert w \\rVert^2_2}} = \\frac{1}{2N} \\sum_{n=1}^{N} \\left( y_n - x_n \\cdot w \\right)^2 {\\color{red}{+ \\frac{1}{2} \\lambda' \\sum_{i=1}^{d_{x}} w_i^2}}\n",
    "\\end{equation}\n",
    "\n",
    "where the minimisation also takes into account the value (norm) of the weights $w_i$. Here, $d_x$ indicates the dimensions of our input $X$, e.g. $d_x=8$ in the case of the polynomial model above. The solution to this minimisation is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    w_\\text{ridge} = \\left({\\color{red}{\\lambda \\mathbb{1}_{d_x} +}} X^\\top X \\right)^{-1} X^\\top Y.\n",
    "\\end{equation}\n",
    "\n",
    "Let's see what happens with this additional term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a0ff3-bbc4-49bd-b98a-844f300d4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ridge = 100000\n",
    "\n",
    "XT = np.transpose(X_poly)\n",
    "XTX_ridge_inverse = np.linalg.inv(XT @ X_poly + lambda_ridge * np.identity(X_poly.shape[1]))\n",
    "\n",
    "w_ridge = XTX_ridge_inverse @ XT @ Y\n",
    "\n",
    "print(f\"Solutions: \\n w_OLS = \\t {w_OLS.squeeze()},\\n w_ridge = \\t {w_ridge.squeeze()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21dc28-0c47-4928-98a0-59efbbccd4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ridge = X_poly @ w_ridge \n",
    "Y_ridge_test = X_test @ w_ridge \n",
    "\n",
    "Rsquared_ridge = 1 - np.sum((Y - Y_ridge)**2) / np.sum((Y - np.mean(Y))**2)\n",
    "\n",
    "print(Rsquared_ridge)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,4))\n",
    "\n",
    "axs[0].scatter(X, Y, marker='o', color='red', label='Observations (with noise)')\n",
    "axs[0].plot(X, Y_groundtruth, color='red', linestyle='dashed', label='Groundtruth')\n",
    "axs[0].scatter(X, Y_OLS, color='blue', marker='X', label=f'Train; OLS with $R^2={Rsquared:.2f}$')\n",
    "axs[0].scatter(X, Y_ridge, color='green', marker='+', label=f'Train; ridge with $R^2={Rsquared_ridge:.2f}$')\n",
    "\n",
    "axs[1].scatter(X, Y, marker='o', color='red', label='Observations (with noise)')\n",
    "axs[1].plot(X, Y_groundtruth, color='red', linestyle='dashed', label='Groundtruth')\n",
    "axs[1].plot(X_test[:,0], Y_OLS_test, color='blue', label=f'Test; OLS')\n",
    "axs[1].plot(X_test[:,0], Y_ridge_test, color='green', label=f'Test; ridge')\n",
    "\n",
    "\n",
    "axs[0].set_xlabel('X')\n",
    "axs[0].set_ylabel('Y')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_xlabel('X')\n",
    "axs[1].set_ylabel('Y')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa92839-1fe0-481a-aa34-e1b365b3149d",
   "metadata": {},
   "source": [
    "#### Note\n",
    "that the additional term $\\lambda \\lVert w \\rVert^2_2 = \\lambda \\sum_{i=1}^{d_{x}=8} w_i^2$ \n",
    "in the loss function enables deviation from the observed noisy datapoints. That is models (i.e.\n",
    "weights $w_i$) which too closely *overfit* to the noisy observations are penalised. Parameter $\\lambda$\n",
    "serves as a **penalty factor** biasing towards *simpler* models which **reduce overfitting**.\n",
    "\n",
    "Generally, having terms in your loss function favouring simpler models is referred to as **regularisation** ([Wikipedia](https://en.wikipedia.org/wiki/Regularization_(mathematics))). Highly-flexible models (like the blue curve in the next figure) allow fitting observations (red dots) arbitrary well. Typically, we prefer to choose simpler models (like the green curve) which usually provide better predictions to new, unseen data (**generalisation**). \n",
    "\n",
    "<center><img src=\"images/Regularisation.png\" alt=\"Regularistation\" width=\"200\"/> <br> Image source: <a href=\"https://en.wikipedia.org/wiki/Regularization_(mathematics)#/media/File:Regularization.svg\">Wikipedia</a> <br> </center>\n",
    "\n",
    "***\n",
    "\n",
    "## Using scikit-learn for Regression\n",
    "\n",
    "You don't need to do all the work yourself! ```scikit-learn``` offers you the required functionality with the functions [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec7a8e-ac4e-4264-a5ed-e31f48fa3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "linreg = LinearRegression(fit_intercept=False)\n",
    "linreg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7bb0a-d924-45e3-9918-ac9c299ab10e",
   "metadata": {},
   "source": [
    "#### Note \n",
    "that we used ```fit_intercept=False``` because we chose to neglect on off-set / intercept $b$ on the y-axis.\n",
    "That is, we consider $Y = Xw + b + \\epsilon$ with $b=0$, which simplifies writing the equations out.\n",
    "\n",
    "```linreg``` is the linear fit which provides you the same OLS solution as seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a740c-d0d0-4f11-aacb-b0fa2e9668a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_OLS_sk = linreg.coef_\n",
    "Y_OLS_sk = linreg.predict(X)\n",
    "Rsquared_sk = linreg.score(X,Y)\n",
    "\n",
    "print(f\"w_OLS_sk = {w_OLS_sk.squeeze()}, Rsquared_sk = {Rsquared_sk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62dadc-9ced-43d5-8d23-e5489ebc30e2",
   "metadata": {},
   "source": [
    "We can do the same for the ridge regression case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596589a-98e7-48fe-8de8-058f7d6d72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgereg = Ridge(fit_intercept=False)\n",
    "ridgereg.fit(X,Y)\n",
    "\n",
    "w_ridge_sk = ridgereg.coef_\n",
    "Y_ridge_sk = ridgereg.predict(X)\n",
    "Rsquared_ridge_sk = ridgereg.score(X,Y)\n",
    "\n",
    "print(f\"w_ridge_sk = {w_ridge_sk.squeeze()}, Rsquared_ridge_sk = {Rsquared_sk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa199b08-a918-4793-a960-94f7e474f735",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Logistic Regression for Classification\n",
    "\n",
    "Next, we consider binary classification where our data falls into one of two classes which we will denote\n",
    "with class labels $Y=0$ (class 1) and $Y=1$ (class 2). Let's assume that observations of \n",
    "class 2 occur with an unkown probability of $p_2$. As we only have to classes,\n",
    "the probablity for class 1 is $p_1 = 1 - p_2$. A natural choice in such a setting is the **Bernoulli distribution** \n",
    "([Wikipedia](https://en.wikipedia.org/wiki/Bernoulli_distribution)) with probability (mass) function\n",
    "\n",
    "\\begin{equation}\n",
    "    p(Y) = p_2^Y p_1^{1-Y} = p_2^Y (1-p_2)^{1-Y}.\n",
    "\\end{equation}\n",
    "\n",
    "The idea of logistic regression is to approximate the ratio of the two class probabilites with an exponential \n",
    "function of the form\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{p_2}{p_1} = \\exp (x_1 \\cdot w_1 + x_2 \\cdot w_1\\cdot w_2 + ... + x_{d_x} \\cdot w_{d_x}) = \\exp (Xw),\n",
    "\\end{equation}\n",
    "\n",
    "so again a linear model! Note that we can write this as\n",
    "\n",
    "\\begin{equation}\n",
    "     \\exp (Xw) = \\frac{p_2}{1-p_2} \\Rightarrow  p_2 = \\frac{1}{1+\\exp (-Xw)}.\n",
    "\\end{equation}\n",
    "\n",
    "This is the **logistic function**. In order to identify the weights $w$, i.e. a matching model, we use the **logistic loss** (also known as **negative log-likelihood** or **cross entropy loss**, depending on the context)\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{Loss}(w) = - Y \\log p_2 - (1-Y) \\log (1-p_2) = - \\sum_{n=1}^{N} y_n \\log \\frac{1}{1+\\exp (-x_n \\cdot w)} + (1-y_n) \\log \\Big(1-\\frac{1}{1+\\exp (-x_n \\cdot w)}\\Big)\n",
    "\\end{equation}\n",
    "\n",
    "for $N$ datapoints. \n",
    "\n",
    "Let's create a simple binary classification problem with $50$ datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef4715-2680-45dd-a252-a43cf3f40eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "num_datapoints = 50\n",
    "\n",
    "X, Y = make_classification(n_samples=num_datapoints, n_features=1, n_informative=1, n_redundant=0, \n",
    "                           n_classes=2, n_clusters_per_class=1, weights=[0.3, 0.7],\n",
    "                           random_state=0)\n",
    "\n",
    "plt.scatter(X[Y == 0], Y[Y == 0], color='blue', marker='+', label='Class 1 encoded by Y=0')\n",
    "plt.scatter(X[Y == 1], Y[Y == 1], color='green', marker='x', label='Class 2 encoded by Y=1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2d413-6544-44ed-944a-1b1405bd0abb",
   "metadata": {},
   "source": [
    "Here we directly use ```scikit-learn``` function [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09963ea-c2c6-47cf-9bde-63c6e01ad441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6ec6a-664b-424d-9e1b-83224409ecf3",
   "metadata": {},
   "source": [
    "Using the method ```predict_proba``` allows predicting the probability \n",
    "$p(Y=1)$ for class 2 of our logistic regression model ```logreg```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5f98a-aa3b-4f77-b19a-cdf0ccef6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_logreg = np.linspace(-2, 2, 1000).reshape(-1, 1)\n",
    "Y_logreg = logreg.predict_proba(X_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7d298-70b6-45f8-b47c-54fc3945e06a",
   "metadata": {},
   "source": [
    "Let's plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29977c4c-dd39-4dcc-b789-ec064c2dc400",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[Y == 0], Y[Y == 0], color='blue', marker='+', label='Class 1 encoded by Y=0')\n",
    "plt.scatter(X[Y == 1], Y[Y == 1], color='green', marker='x', label='Class 2 encoded by Y=1')\n",
    "plt.plot(X_logreg[:, 0], Y_logreg[:, 1], color='red', label='Logistic Regression')\n",
    "plt.axhline(0.5, color='black', linestyle='--', label='Threshold')\n",
    "\n",
    "plt.xlabel('Predictor X')\n",
    "plt.ylabel(r'Class porbability $P(Y=1)$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f85f20b-ef76-4f19-ba63-fdf3c468daa2",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Decision Trees and Random Forests\n",
    "\n",
    "An more classical approach to classification problems are decision trees. \n",
    "In the next example, we will try to classify premium red wine from their \n",
    "measured propertes / features which serve as the predictors / covariates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749d377-f80b-40c6-8c58-6b0f49c24968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wine_data = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "\n",
    "quality_threshold = 6\n",
    "# quality_threshold = 5\n",
    "\n",
    "wine_data['premium'] = wine_data['quality'] > quality_threshold\n",
    "\n",
    "wine_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d4a5d-cf60-4d46-9d31-ebb27ff84c68",
   "metadata": {},
   "source": [
    "We focus on the quality assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1e177-a0a0-462f-8ea5-62856d7bb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_counts = wine_data['quality'].value_counts()\n",
    "\n",
    "if quality_threshold == 5:\n",
    "    colours = ['red','blue','blue','red','blue','red']\n",
    "elif quality_threshold == 6:\n",
    "    colours = ['red','red','blue','red','blue','red']\n",
    "\n",
    "print(quality_counts)\n",
    "    \n",
    "plt.bar(quality_counts.index, quality_counts, color=colours)\n",
    "plt.xlabel('Quality assessment')\n",
    "plt.ylabel('Amount of different wines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bac517-2cfb-43b7-8042-2d5848f27768",
   "metadata": {},
   "source": [
    "Perpare the features and target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b632b-ba99-4933-8d49-e6997524b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = wine_data['premium'].astype(int)\n",
    "wine_features = wine_data.drop( ['quality','premium'], axis=1)\n",
    "\n",
    "print(\"Shape of wine_features:\\t{}\\nShape of target:\\t{}\\n\"\n",
    "      .format(wine_features.shape, target.shape)\n",
    "     )\n",
    "\n",
    "target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b80800-e177-4e20-b6eb-d948c72b8a5a",
   "metadata": {},
   "source": [
    "#### The __Goal__\n",
    "is to learn a classifier which predicts whether a wine is a premium /\n",
    "non-premium wine on the basis of the measured wine features.\n",
    "\n",
    "Select (randomly) a set on which the classifier is \n",
    "calibrated / trained on and a test set on which the performance\n",
    "is assessed. We consider a test set size of 30% of the original data\n",
    "set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab24dd-3f27-44df-8e71-32e2df155080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feat_train, feat_test, target_train, target_test = train_test_split(\n",
    "    wine_features, target, test_size = 0.3, random_state=123)\n",
    "\n",
    "print(\"After splitting into train and test sets:\\n\\n\"\n",
    "      f\"Shape of feat_train:\\t{feat_train.shape}\\nShape of target_train:\\t{target_train.shape}\\n\"\n",
    "      f\"Shape of feat_test:\\t{feat_test.shape}\\nShape of target_test:\\t{target_test.shape}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501a504-2fc5-400c-93e9-dc1ef24abf16",
   "metadata": {},
   "source": [
    "We have a first look on a decision tree and just consider the features \n",
    "providing the ```alcohol``` and ```sulphates``` content. We use the [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0403fc8-6585-4af1-8ef1-a6ed8b4dd6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "feat_train_subset = feat_train[ ['alcohol','sulphates'] ]\n",
    "\n",
    "wine_tree = DecisionTreeClassifier(max_depth=2)\n",
    "wine_tree.fit(feat_train_subset, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe262a32-72dd-45df-85cc-7e11305bc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "try:\n",
    "    from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "    display = DecisionBoundaryDisplay.from_estimator(\n",
    "        wine_tree,\n",
    "        feat_train_subset,\n",
    "        cmap='RdYlBu',\n",
    "        response_method=\"predict\",\n",
    "        ax=axs[0],\n",
    "        xlabel='alcohol',\n",
    "        ylabel='sulphates',\n",
    "    )\n",
    "except:\n",
    "    print(\"Sorry, the library for plotting the decision \" \n",
    "          \"boundary is currently missing\")\n",
    "\n",
    "plot_tree(wine_tree, max_depth=2, \n",
    "          feature_names=['alcohol','sulphates'], \n",
    "          class_names=['non-premium','premium'],\n",
    "          ax=axs[1], fontsize=7, filled = True,\n",
    "         )\n",
    "\n",
    "\n",
    "axs[0].scatter(feat_train['alcohol'], feat_train['sulphates'],\n",
    "               c=target_train, cmap='RdYlBu', edgecolor='black'\n",
    "              )\n",
    "\n",
    "plt.tight_layout()                        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc58a9b-8cd9-4b70-99ca-b3737350421d",
   "metadata": {},
   "source": [
    "#### Note \n",
    "that decision trees partition the input space into different regions with \n",
    "**decision boundaries** separating different classes, like premium wines \n",
    "(blue data / region) and non-premium wines (red data / region)!\n",
    "\n",
    "Now let's consider the full dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fa222-e23c-495d-aa8d-425250006e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_height = 8\n",
    "\n",
    "wine_tree = DecisionTreeClassifier(max_depth=tree_height)\n",
    "wine_tree.fit(feat_train, target_train)\n",
    "\n",
    "correct_pred = wine_tree.predict(feat_test) == target_test\n",
    "\n",
    "correct = correct_pred.value_counts()\n",
    "\n",
    "accuracy = (correct[True] / (correct[True] + correct[False]))*100\n",
    "print(f\"The random forest identified premium / non-premium wines with {accuracy}% accuracy!\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(100,20))\n",
    "\n",
    "plot_tree(wine_tree, \n",
    "          feature_names=wine_features.columns.to_list(), \n",
    "          class_names=['non-premium','premium'],\n",
    "          filled = True,\n",
    "          ax=ax,\n",
    "          fontsize=8\n",
    "         )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d87c2-2652-435a-8cd5-f35176f61423",
   "metadata": {},
   "source": [
    "#### You can learn more on decision trees \n",
    "from [scikit-learn](https://scikit-learn.org/stable/modules/tree.html) and\n",
    "the [mathematical criteria](https://scikit-learn.org/stable/modules/tree.html#tree-mathematical-formulation) for the decision splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77143e-28b7-4064-b056-87844844dd96",
   "metadata": {},
   "source": [
    "#### **Random Forests**\n",
    "are now very powerful machine learning methods which build on decision trees. \n",
    "Random Forests construct a multitude of decision trees like the one above. \n",
    "The individual decision trees provide a classification result and by majority \n",
    "voting the final classification is obtained. We use the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0c395-54e3-45b3-8863-8848ef5addf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_trees = 100\n",
    "tree_height = 8\n",
    "\n",
    "wine_forest = RandomForestClassifier(n_estimators=num_trees, \n",
    "                                       max_depth=tree_height, \n",
    "                                       random_state=123)\n",
    "wine_forest.fit(feat_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af5325-84e0-4054-bae7-bbc141fab016",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = wine_forest.predict(feat_test) == target_test\n",
    "\n",
    "correct = correct_pred.value_counts()\n",
    "\n",
    "accuracy = (correct[True] / (correct[True] + correct[False]))*100\n",
    "print(f\"The random forest identified premium / non-premium wines with {accuracy}% accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c262762-cb4c-48cc-a840-2317c7fd633e",
   "metadata": {},
   "source": [
    "#### That's a great accuracy! But\n",
    "let's check what is actually predicted wrongly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b37a4-7df0-4c4b-855f-11ad4e981581",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_incorrect_pred = target_test[correct_pred == False].value_counts() / target_test.value_counts()\n",
    "\n",
    "print(f\"Incorrect predictions by premium quality:\\n{rel_incorrect_pred}\")\n",
    "print(f\"\\nRatio of premium / non-premium wines in test set:\\n{target_test.value_counts(normalize=True)}\")      \n",
    "print(f\"\\nRatio of premium / non-premium wines in train set:\\n{target_train.value_counts(normalize=True)}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57bc88-6865-4a6e-959a-6c4ee79d99eb",
   "metadata": {},
   "source": [
    "You can still plot one of the trees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce4983-8607-4a81-9327-9f827321d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree = wine_forest.estimators_[5]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(100,20))\n",
    "\n",
    "plot_tree(single_tree, \n",
    "          feature_names=wine_features.columns.to_list(), \n",
    "          class_names=['non-premium','premium'],\n",
    "          filled = True,\n",
    "          ax=ax,\n",
    "          fontsize=8\n",
    "         )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1f6f7-a9b8-49f7-b78c-afd96c9609e4",
   "metadata": {},
   "source": [
    "However, this is less insightful, as the decision is made by vote of many (different) trees!\n",
    "Still, we can study the **feature importance score**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d368cb6-fa29-4ab2-b56a-022cbef9bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = wine_forest.feature_importances_\n",
    "feature_names = list(wine_features.columns)\n",
    "\n",
    "important_features = pd.Series(feature_scores, index=feature_names).sort_values()\n",
    "\n",
    "plt.barh(important_features.index, important_features, color='Orange')\n",
    "plt.xlabel('Feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fc421-3bad-45d3-b4c9-609dcdc99a5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Exercise Section\n",
    "\n",
    "(1.) In this exercise, we train a ```Ridge``` regressor for predicting the ```quality``` values on the test set ```feat_test```. \n",
    "First, load the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a7868-b8ee-42ce-82ea-b5e117f927ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine_data = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "\n",
    "ex_target = wine_data['quality']\n",
    "ex_features = wine_data.drop(['quality'], axis=1)\n",
    "\n",
    "feat_train, feat_test, target_train, target_test = train_test_split(\n",
    "    ex_features, ex_target, test_size = 0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98c1f0-7c8d-4487-afc8-8d39be2e0ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf096b9-8a19-40fe-b698-65452ce3aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0cd99-4058-41e8-b79a-06752e1f0358",
   "metadata": {},
   "source": [
    "Put your result in the next cell and use ```ex_pred_ridge``` for the predicted quality values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4296e-a8cf-4998-8b5f-173bbf775e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Fill in\n",
    "\n",
    "ex_pred_ridge = # Fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92633f48-dba6-4b67-82d6-50239be0d28d",
   "metadata": {},
   "source": [
    "Execute the next cell to save the results in a summary data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7cf3ee-d214-449e-bff5-b530affe9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = target_test.to_frame()\n",
    "target_test['Ridge_predicted_quality'] = np.around(ex_pred_ridge, decimals=2)\n",
    "target_test['Ridge_absolut_deviation'] = abs(target_test['quality'] - target_test['Ridge_predicted_quality'])\n",
    "target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638620c7-c7cb-4a43-9c52-22104c01cfce",
   "metadata": {},
   "source": [
    "(2.) You can create a Random Forest not only for classification, but also regression. Make use of the ```scikit-learn``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e102138-2d17-48e5-9459-528f565ae1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf4697-2ae8-4455-b901-9eb87acf678f",
   "metadata": {},
   "source": [
    "to make predictions on the wine quality based on the other features / predictors. Load the previous cell\n",
    "and train a the ```RandomForestRegressor``` for predicting the quality values on the test set ```feat_test```. Put your result in the next cell and use ```ex_pred_RF``` for the predicted quality values.\n",
    "\n",
    "Hint: You might want to revisit the steps for RF classification we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d880e0-62df-45d8-9e12-a0850d474944",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 100\n",
    "tree_height = 8\n",
    "\n",
    "# Fill in\n",
    "\n",
    "ex_pred_RF = # Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc2fec-ee1a-4b0f-a24a-5ae1c2ec1f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test['RF_predicted_quality'] = np.around(ex_pred_RF, decimals=2)\n",
    "target_test['RF_absolut_deviation'] = abs(target_test['quality'] - target_test['RF_predicted_quality'])\n",
    "target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1769f2-4942-4c75-94ac-01c90a83f4c5",
   "metadata": {},
   "source": [
    "Finally, compare how the Random Forest and ridge regressor performed in comparison.\n",
    "For this, just execute the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099af4d-4ef6-46bb-a147-fbbf6b239dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pred_MSE = (target_test['RF_absolut_deviation']**2).mean()\n",
    "Ridge_pred_MSE = (target_test['Ridge_absolut_deviation']**2).mean()\n",
    "\n",
    "print(f\"Mean squared error of RandomForestRegressor: {RF_pred_MSE:.2f}\")\n",
    "print(f\"Mean squared error of Ridge: {Ridge_pred_MSE:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
