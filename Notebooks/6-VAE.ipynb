{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e4a700-e3e7-43f5-a0f7-cf12f37b682c",
   "metadata": {},
   "source": [
    "# 6. Variational Autoencoder\n",
    "\n",
    "We have seen approaches for compression previously. In this notebook, we cover a related\n",
    "approach based on neural networks which also enables us to generate novel (artificial) data. \n",
    "\n",
    "In particular, we discuss \n",
    "\n",
    "* latent variable models and\n",
    "* the Variational Autoencoder\n",
    "\n",
    "and provide a more advanced CNN implementation for MNIST and a molecule dataset.  \n",
    "\n",
    "Keywords: ```VAE```, ```ELBO```, ```reparameterisation trick```, ```keras.Model```, ```keras.layers.Conv2DTranspose```,\n",
    "```tensorflow.GradientTape```, ```tf.sigmoid```, ```model.save_weights```, ```model.load_weights```, ```keras.optimizers.Adam```\n",
    "\n",
    "***\n",
    "\n",
    "## Latent Variable Models\n",
    "\n",
    "Latent variable models (LVMs) are statistical models which consider random variables.\n",
    "Suppose that our observations $X$ and $Y$ are random variables following a probability \n",
    "distribution $p(X,Y)$. LVMs assume that there are **latent, i.e. unobserved or hidden, variables** $Z$\n",
    "which have a relationship to our observed data $X$ and $Y$. A typical assumption, for instance is,\n",
    "that our predictors $X$ are generated by **lower-dimensional latent variables** $Z$, e.g. $p(X \\mid Z)$. \n",
    "\n",
    "Note that we have seen models such as these already. For example, in a **Gaussian Mixture Model** datapoints $X_i$ belonging to cluster $i$ with mean $\\mu_i$ and covariance matrix $\\Sigma_i$ are generated by sampling from\n",
    "$\\mathcal{N}(\\mu_i, \\Sigma_i)$. In other words, the low-dimensional latent variables are $Z=(\\mu, \\Sigma)$. **PCA** is another example where few principal components can allow describing the majority of variation in a dataset. However, these **linear LVMs** assume linear relationships between latent variable $Z$ and the observations.\n",
    "\n",
    "Due to the highly non-linear nature of neural networks, we can use neural networks to extend models such as PCA to\n",
    "**non-linear LVMs**. Here, we pick up the previously encountered idea of compression:\n",
    "\n",
    "<br><center><img src=\"images/Compression.png\" alt=\"Image compression with Fast Fourier Transform\" width=\"600\"/></center></br>\n",
    "\n",
    "The **Variational Autoencoder (VAE)** is an unsupervised neural network approach which attempts to identify a\n",
    "meaningful **latent representation** $Z$ capable of reconstructing the original input as perfectly as possible. \n",
    "The VAE can be viewed as probabilistic non-linear PCA, with the general idea being illustrated in the following figure.\n",
    "\n",
    "<center><img src=\"images/VAE_idea.png\" alt=\"Variational Autoencoder Illustration\" width=\"400\"/></center>\n",
    "\n",
    "The VAE has three important components:\n",
    "\n",
    "1. **Enocoder**: The encoder neural network attempts to compress the relevant information about $X$ in latent representation $Z$ with dimensions $d_X > d_Z$. The goal of the encoder is to parameterise a distribution $q_\\phi (Z \\mid X)$ which provides us a (variational) approximation for the distribution of the (compressed) latent variables $Z$ given an input $X$. Here, $\\phi$ denotes the weights of the encoder network. We typically assume that this approximation is given by a Gaussian distribution $\\mathcal{N} (\\mu_Z,\\Sigma_Z)$ where $\\mu_Z=(\\mu_1, \\dots, \\mu_{d_Z})$ and $\\Sigma_Z=(\\sigma_1, \\dots, \\sigma_{d_Z})$ containing only the diagonal entries of covariance matrix $\\Sigma_Z$ (all other entries are 0). For technical reasons (details omitted), we require the **reparameterisation trick** to sample latent variables $Z$: $$z_n( \\varepsilon ) = \\mu_{Z}(x_n) + \\Sigma^2_{Z}(x_n)  \\varepsilon$$ with $\\varepsilon\\sim\\mathcal{N}(0,1)$.\n",
    "\n",
    "2. **Latent representation / space** $Z$: Datapoints from the input space are mapped into the lower-dimensional latent space $Z$. To start with, we typically assume that the latent variables $Z$ are normally distributed, i.e. a prior distribution $p(Z) = \\mathcal{N} (0,\\mathbb{1}_{d_Z})$ with $d_Z$ being the number of latent dimensions. We train the encoder such that the (posterior) distribution $q_\\phi (Z \\mid X)$ matches the prior $p(Z)$ as much as possible. The deviations from the prior distribution will capture important features of our dataset. We measure the difference in these distributions with the (non-negative) [Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) $$D_\\text{KL} \\big(q_{\\phi}(Z \\mid X) \\Vert p(Z) \\big) = - \\frac{1}{2} \\sum_{i=1}^{d_Z} (1 + \\log \\sigma_i^2 - \\mu_i^2 - \\sigma_i^2),$$ where the last expression follows from the Gaussian distrubtion assumptions outlined before.\n",
    "\n",
    "3. **Decoder**: The decoder neural network attempts so reconstruct the original input $X$ from the compressed representation $Z$. The goal of the decoder is to parameterise the likelihood $p_\\theta (X \\mid Z)$ with decoder network weights $\\theta$. The **reconstruction error** is measured by the log-likelihood $\\log (p_\\theta (X \\mid Z))$ which in the case of regression tasks is typically given by the mean-squared error loss and in classification tasks by the cross-entropy loss.\n",
    "\n",
    "Combining these ingredients, we obtain the VAE loss function which is usually referred to as negative **evidence lower bound (ELBO)**\n",
    "\n",
    "\\begin{equation}\n",
    "   \\text{Loss} (\\phi, \\theta)= \\frac{1}{s} \\sum_{i=1}^{s} \\underbrace{\\mathbb{E}_{q_{\\phi} (z \\vert x_i)} \\big(- \\log (p_{\\theta}(x_i \\vert z)) \\big)}_\\text{reconstruction loss} + \\underbrace{D_\\text{KL} \\big( q_{\\phi}(z \\vert x_i) \\Vert p(z) \\big)}_\\text{latent loss}\n",
    "\\end{equation}\n",
    "\n",
    "where $s$ is the batch size (denoting that we sum the results for different batches). Note that the VAE objective has two parts which we try to balance:\n",
    "\n",
    "1. The **reconstruction loss** measures how well we can reconstruct the input $X$ from the compression $Z$. In other words, this term is an incentive to provide as much information of $X$ in $Z$ as possible, i.e. less compression.\n",
    "2. The **latent loss** measures how well the posterior $q_{\\phi}(Z \\mid X)$ agrees with the prior $p(Z)$. This term favours stronger compressions.\n",
    "\n",
    "With this probabilistic framework, we can now explore the latent space $Z$ and, in particular, pick\n",
    "latent points in $Z$ to generate novel artifical objects by decoding the picked latent point!\n",
    "\n",
    "Let's implement and apply a VAE on MNIST! For this, we first define \n",
    "a class for the model which provides the individual parts as outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20827b2-d21a-4b3d-8f4d-ad69987ad55f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class VAE(keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, batch_size):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Encoder network:\n",
    "        self.encoder = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "                keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                keras.layers.Flatten(),\n",
    "                keras.layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Decoder network:\n",
    "        self.decoder = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                keras.layers.Dense(units=7 * 7 * 32, activation='relu'),\n",
    "                keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "                keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "                keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "                keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(self.batch_size, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    \n",
    "    # Reparameterisation trick:\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=(self.batch_size, self.latent_dim))\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    \n",
    "    def call(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return self.decoder(z), mean, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22bf423-8aab-432e-a95f-ce0b4eebd5b9",
   "metadata": {},
   "source": [
    "Furthermore, we define some functions we will use for computing the loss and \n",
    "the training steps. Note that in the previous notebook we used some built-in\n",
    "```keras``` functions for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97945e3e-69d9-4421-9298-7a0048d6f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2.0 * np.pi)\n",
    "    return tf.reduce_sum(-0.5 * ((sample - mean) ** 2.0 * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1d000-54f1-4027-8c61-5ecebf91113f",
   "metadata": {},
   "source": [
    "Now, we can load MNIST as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3a93b-4505-4bac-b331-c17e8cc7dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = np.load('data/mnist_data_5k.npy', allow_pickle=True).astype('float32')\n",
    "mnist_targets = np.load('data/mnist_labels_5k.npy', allow_pickle=True).astype('float32')\n",
    "\n",
    "mnist_data = mnist_data.reshape(-1, 28, 28, 1) / 255\n",
    "\n",
    "num_train = 3000\n",
    "num_val = 1000\n",
    "num_test = 1000\n",
    "\n",
    "x_train = mnist_data[:num_train]\n",
    "y_train = mnist_targets[:num_train]\n",
    "\n",
    "x_val = mnist_data[num_train:num_train+num_val]\n",
    "y_val = mnist_targets[num_train:num_train+num_val]\n",
    "\n",
    "x_test = mnist_data[-num_test:]\n",
    "y_test = mnist_targets[-num_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351d20b-14b2-43a7-8e19-f6e0f627fb29",
   "metadata": {},
   "source": [
    "Define the hyperparameters, the model, and the optimiser, where we choose the [Adam optimiser](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b253a-f39d-496d-8919-d46be3437283",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "latent_dim = 2\n",
    "\n",
    "vae_model = VAE(latent_dim, batch_size)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03269c6f-04c9-4f7f-870f-4650dfad2c49",
   "metadata": {},
   "source": [
    "In the following, we write our own loop for training and validation.\n",
    "\n",
    "**For Noto users**: Please note that the training can take several minutes on Noto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cdc2f-d7e9-4f36-b6e8-eefa098f62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "    # Training steps\n",
    "    for i in range(num_train // batch_size):\n",
    "        train_step(vae_model, x_train[i:i + batch_size], optimizer)\n",
    "\n",
    "    # Validation steps\n",
    "    r_val = num_val // batch_size\n",
    "    loss = keras.metrics.Mean()\n",
    "    elbo = 0\n",
    "\n",
    "    for i in range(r_val):\n",
    "        loss(compute_loss(vae_model, x_val[i:i + batch_size]))\n",
    "        elbo += -loss.result()\n",
    "\n",
    "    elbo /= r_val\n",
    "\n",
    "    print(f'Epoch: {epoch}/{num_epochs}, validation loss (ELBO): {elbo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b944e7d-fbfa-46d2-911d-6cbc3f8f5bc3",
   "metadata": {},
   "source": [
    "For our custom model, we need to store the trained weights in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a70c29-d56d-4085-aa74-2c9c5041f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.save_weights('output/MNIST_VAE.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4836eef-0a89-4fef-85c7-cfd540491e7f",
   "metadata": {},
   "source": [
    "You can load a pretrained model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5e38e-3472-410c-b5a4-9f03e8de4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = VAE(latent_dim, num_test)\n",
    "vae_model(x_test)  # For input dimension specification\n",
    "\n",
    "# Our pretrained model (300 epochs):\n",
    "# vae_model.load_weights('output/MNIST_VAE_pretrained.h5')\n",
    "\n",
    "# ... or load your model:\n",
    "vae_model.load_weights('output/MNIST_VAE.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f4ff0-9451-4b2f-b8e3-1597800df2b1",
   "metadata": {},
   "source": [
    "Let's check out the results for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74220ead-4c47-40a9-b96e-fe68ae93ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_z, logvar_z = vae_model.encode(x_test)\n",
    "latent_z = vae_model.reparameterize(mean_z, logvar_z)\n",
    "predictions = vae_model.sample(latent_z)\n",
    "\n",
    "fig, axs = plt.subplots(1,10, figsize=(10,5))\n",
    "\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(predictions[i])\n",
    "    \n",
    "    ax.set_title(f\"Label: {int(y_test[i])}\", fontsize=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78f2b3-28eb-4c64-891b-ade70f5f8fae",
   "metadata": {},
   "source": [
    "We can also investigate where the test datapoints lie in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8134a0-af44-4460-a7ad-8b4d68e4648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(latent_z[:, 0], latent_z[:, 1], c=y_test, cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.xlabel(r\"Latent dim. $Z_0$\")\n",
    "plt.ylabel(r\"Latent dim. $Z_1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3069b-17b7-414c-866d-8c14efb1d6f7",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Variational Autoencoder for Molecules\n",
    " \n",
    "*(Note that in this part you might not be able to execute all cells -- in particular on Noto!)*\n",
    "\n",
    "In the following we apply the VAE-idea on a molecular dataset and train a **Chemical VAE**. In addition to the standard VAE, we also predict a chemical property $Y$. This allow us to do a **guided search of novel molecules** which match a property of our interest.\n",
    "\n",
    "<center><img src=\"images/Molecule_example.png\" alt=\"VAE for Molecules\" width=\"400\"/></center>\n",
    "\n",
    "As illustrated above, we predict a chemical property with an **additional decoder network** directly from the latent sample. This does not only provide additional information about the molecules, but also structures the latent representation $Z$ with resprect to property $Y$. This will have the effect the chemical property will gradually change within the latent space.\n",
    "\n",
    "\n",
    "So far, we have worked with tabular data and images as inputs. Molecules can be represented in variouse ways. A common representation is a graph. Here, the nodes of a molecular graph are the atoms and the edges are molecular bonds. A popular and simple depiction of a molecular graph is a so-called **SMILES representation**. It is a text string that encloses all the information required to convert it to a graph.\n",
    "\n",
    "For our experiments we will use a variant called the **Deep-SMILES representation** which makes generation of valid molecular structures easier.\n",
    "\n",
    "Let's have a closer look on the dataset and how these SMILES and Deep-SMILES look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7ed573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>deep_smiles</th>\n",
       "      <th>band_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.3399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.3615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>C#C</td>\n",
       "      <td>C#C</td>\n",
       "      <td>0.3351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>0.4426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>CO</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.3437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31667</th>\n",
       "      <td>41529</td>\n",
       "      <td>C1CC2=CCCOCC12</td>\n",
       "      <td>CCC=CCCOCC97</td>\n",
       "      <td>0.2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31668</th>\n",
       "      <td>41530</td>\n",
       "      <td>C1CC2=CCOCCC12</td>\n",
       "      <td>CCC=CCOCCC97</td>\n",
       "      <td>0.2528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31669</th>\n",
       "      <td>41531</td>\n",
       "      <td>C1CC2=CCOCOC12</td>\n",
       "      <td>CCC=CCOCOC97</td>\n",
       "      <td>0.2504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31670</th>\n",
       "      <td>41533</td>\n",
       "      <td>C1OC2=NCCCCC12</td>\n",
       "      <td>COC=NCCCCC97</td>\n",
       "      <td>0.2701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31671</th>\n",
       "      <td>41535</td>\n",
       "      <td>C1OC2=NCCCOC12</td>\n",
       "      <td>COC=NCCCOC97</td>\n",
       "      <td>0.2648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31672 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          smiles   deep_smiles  band_gap\n",
       "0          2               N             N    0.3399\n",
       "1          3               O             O    0.3615\n",
       "2          4             C#C           C#C    0.3351\n",
       "3          7              CC            CC    0.4426\n",
       "4          8              CO            CO    0.3437\n",
       "...      ...             ...           ...       ...\n",
       "31667  41529  C1CC2=CCCOCC12  CCC=CCCOCC97    0.2548\n",
       "31668  41530  C1CC2=CCOCCC12  CCC=CCOCCC97    0.2528\n",
       "31669  41531  C1CC2=CCOCOC12  CCC=CCOCOC97    0.2504\n",
       "31670  41533  C1OC2=NCCCCC12  COC=NCCCCC97    0.2701\n",
       "31671  41535  C1OC2=NCCCOC12  COC=NCCCOC97    0.2648\n",
       "\n",
       "[31672 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "molecule_data = pd.read_pickle('data/molecule_data.pkl')\n",
    "molecule_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a7c85",
   "metadata": {},
   "source": [
    "We can now plot the first and the last molecules from the dataset as chemical graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5d8dfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chem\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mChem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Draw\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "smiles_list = molecule_data['smiles'].values[0:20]\n",
    "molecule_list = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
    "figure = Draw.MolsToGridImage(molecule_list, molsPerRow=5, subImgSize=(100, 100), returnPNG=False)\n",
    "\n",
    "plt.imshow(figure)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86caa3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = molecule_data['smiles'].values[31650:31670]\n",
    "molecule_list = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
    "figure = Draw.MolsToGridImage(molecule_list, molsPerRow=5, subImgSize=(100, 100), returnPNG=False)\n",
    "\n",
    "plt.imshow(figure)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f0271",
   "metadata": {},
   "source": [
    "Let's define some functions which help us to convert deep-smiles into a one-hot representation and normalise the property values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_onehot(deep_smiles):\n",
    "\n",
    "    max_len = max([len(x) for x in deep_smiles])\n",
    "    data = []\n",
    "\n",
    "    for item in deep_smiles:\n",
    "        ch_lst = list(item) + (max_len - len(item)) * [stop_character]\n",
    "\n",
    "        res = []\n",
    "\n",
    "        for ch in ch_lst:\n",
    "            r = [0] * len(chars)\n",
    "            r[chars.index(ch)] = 1\n",
    "            res.append(r)\n",
    "\n",
    "        data.append(res)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def one_hot_to_smiles(data, chars, stop_character):\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for item in data:\n",
    "        ch_lst = []\n",
    "\n",
    "        for ch in item:\n",
    "            ch_lst.append(chars[np.argmax(ch)])\n",
    "\n",
    "        res.append(''.join(ch_lst).split(stop_character)[0])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def sparse_to_smiles(data):\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for item in data:\n",
    "        ch_lst = []\n",
    "\n",
    "        for ch in item:\n",
    "            ch_lst.append(chars[ch[0]])\n",
    "\n",
    "        res.append(''.join(ch_lst))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa00000",
   "metadata": {},
   "source": [
    "First, we shuffel the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecb13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_data = molecule_data.sample(frac=1, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b25fc81",
   "metadata": {},
   "source": [
    "Then, we use our function to convert deep smiles to a one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632614b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_character = 'x'\n",
    "\n",
    "chars = sorted(list(set(''.join(molecule_data['deep_smiles'].values))))\n",
    "chars = chars + [stop_character]\n",
    "\n",
    "print('Unique characters:', chars)\n",
    "\n",
    "data = smiles_to_onehot(molecule_data['deep_smiles'].values)\n",
    "data = np.array(data).reshape((len(data), 17, 15, 1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493916b",
   "metadata": {},
   "source": [
    "and normalise the property values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a485937",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_gap_mean = molecule_data['band_gap'].mean()\n",
    "band_gap_std = molecule_data['band_gap'].std()\n",
    "target = (molecule_data['band_gap'] - band_gap_mean) / band_gap_std\n",
    "target = target.values.reshape((len(data), 1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989510b",
   "metadata": {},
   "source": [
    "As usual, we split the dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 28000\n",
    "num_val = 1000\n",
    "num_test = 1000\n",
    "\n",
    "x_train = data[:num_train]\n",
    "y_train = target[:num_train]\n",
    "\n",
    "x_val = data[num_train:num_train + num_val]\n",
    "y_val = target[num_train:num_train + num_val]\n",
    "\n",
    "x_test = data[num_train + num_val:num_train + num_val + num_test]\n",
    "y_test = target[num_train + num_val:num_train + num_val + num_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065623e6",
   "metadata": {},
   "source": [
    "We can now create our new model ```CVAE``` which provides property predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class CVAE(keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, batch_size):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer(input_shape=(17, 15, 1)),\n",
    "                keras.layers.Flatten(),\n",
    "                keras.layers.Dense(units=1120, activation='relu'),\n",
    "                keras.layers.Dense(units=1120, activation='relu'),\n",
    "                keras.layers.Flatten(),\n",
    "                keras.layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                keras.layers.Dense(units=1120, activation='relu'),\n",
    "                keras.layers.Dense(units=1120, activation='relu'),\n",
    "                keras.layers.Dense(units=255),\n",
    "                keras.layers.Reshape(target_shape=(17, 15, 1)),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Our new decoder:\n",
    "        self.decoder_property = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                keras.layers.Dense(units=1120, activation='relu'),\n",
    "                keras.layers.Dense(units=1120, activation='relu'),\n",
    "                keras.layers.Dense(units=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return self.decoder(z), mean, logvar\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(self.batch_size, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=(self.batch_size, self.latent_dim))\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2.0 * np.pi)\n",
    "\n",
    "    return tf.reduce_sum(-0.5 * ((sample - mean) ** 2.0 * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x, y):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "\n",
    "    # Property\n",
    "\n",
    "    y_pred = model.decoder_property(z)\n",
    "    y_mse = -tf.reduce_mean(tf.square(y - y_pred), axis = 0)\n",
    "\n",
    "    return -tf.reduce_mean(100 * y_mse + logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "def compute_y_mae(model, x, y):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    y_pred = model.decoder_property(z)\n",
    "    y_mae = tf.reduce_mean(tf.abs(y - y_pred), axis = 0)\n",
    "    return y_mae\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, y, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x, y)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d611b24",
   "metadata": {},
   "source": [
    "With this, we can now set the hyperparameters and create our model and optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7db2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 100\n",
    "num_epochs = 31\n",
    "latent_dim = 14\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate)\n",
    "model = CVAE(latent_dim, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0de17-b89b-4718-bfa1-f88eb41e3385",
   "metadata": {},
   "source": [
    "You can try to train this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3594489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "    # Training steps\n",
    "    for i in range(num_train // batch_size):\n",
    "        train_step(model, x_train[i:i + batch_size], y_train[i:i + batch_size], optimizer)\n",
    "\n",
    "    # Validation steps\n",
    "    r_val = num_val // batch_size\n",
    "    loss = keras.metrics.Mean()\n",
    "    elbo = 0\n",
    "    y_loss = 0\n",
    "\n",
    "    for i in range(r_val):\n",
    "        loss(compute_loss(model, x_val[i:i + batch_size], y_val[i:i + batch_size]))\n",
    "        y_loss += compute_y_mae(model, x_val[i:i + batch_size], y_val[i:i + batch_size]).numpy()[0]\n",
    "        elbo += -loss.result()\n",
    "\n",
    "    elbo /= r_val\n",
    "    y_loss = y_loss / r_val * band_gap_std * 627\n",
    "\n",
    "    # Print validation results\n",
    "    print(f'Epoch: {epoch}/{num_epochs}, validation loss (ELBO): {elbo}, Y MAE: {y_loss}')\n",
    "    \n",
    "    if epoch % 10:\n",
    "        path = 'output/Molecules_VAE.h5'\n",
    "        model.save_weights(path, save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e5f6a-b0ce-44fb-be76-891b7ddab198",
   "metadata": {},
   "source": [
    "Alternatively, you can just load the pretrained model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f4620-5201-4638-b17a-210c4ee4136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE(latent_dim, num_test)\n",
    "model(x_test)\n",
    "\n",
    "# Our pretrained model (31 epochs):\n",
    "# model.load_weights('output/Molecules_VAE_pretrained.h5')\n",
    "\n",
    "# ... or load your model:\n",
    "model.load_weights('output/Molecules_VAE.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa3fc82",
   "metadata": {},
   "source": [
    "We can now make predictions with our model and use PCA for dimensionality reduction in order to visualise the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "mean_z, logvar_z = model.encode(x_test)\n",
    "latent_z = model.reparameterize(mean_z, logvar_z)\n",
    "target_pred = model.decoder_property(latent_z).numpy().flatten()\n",
    "\n",
    "# Invert the scaling and convert the property unit to Kcal/mol\n",
    "target_pred = (target_pred * band_gap_std + band_gap_mean) * 627\n",
    "\n",
    "data_pca = PCA(n_components=2)\n",
    "data_pca.fit(mean_z.numpy())\n",
    "data_pca_transform = data_pca.transform(mean_z.numpy())\n",
    "\n",
    "plt.scatter(data_pca_transform[:, 0], data_pca_transform[:, 1], c=target_pred)\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5033c6",
   "metadata": {},
   "source": [
    "In this plot we can see a **smooth transition of the property correspondence making it easy to sample molecules of our interest**. To this end, we can linearly interpolate between two molecules. \n",
    "\n",
    "Let us pick $1000$ datapoints in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775fdeff-4a4a-42ff-a134-b767ed363a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_inter_data = 1000\n",
    "\n",
    "latent_z_inter = np.linspace(mean_z[7:8][0], mean_z[8:9][0], num_inter_data)\n",
    "latent_z_inter_transform = data_pca.transform(latent_z_inter)\n",
    "\n",
    "plt.scatter(data_pca_transform[:, 0], data_pca_transform[:, 1], c=target_pred)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.scatter(latent_z_inter_transform[:, 0], latent_z_inter_transform[:, 1], \n",
    "            marker='.', c='red')\n",
    "\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ad035-0679-4cb1-bf26-76ef70593886",
   "metadata": {},
   "source": [
    "We can now take these latent datapoints and decode molecules and their corresponding property value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba517e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inter_pred = model.decoder(latent_z_inter)\n",
    "target_inter_pred = model.decoder_property(latent_z_inter).numpy()\n",
    "\n",
    "deep_smi_inter_pred = sparse_to_smiles(tf.argmax(data_inter_pred, axis=2).numpy())\n",
    "deep_smi_inter_pred = [item.replace(stop_character, '') for item in deep_smi_inter_pred]\n",
    "\n",
    "deep_smi_inter_pred, idx = np.unique(deep_smi_inter_pred, return_index=True)\n",
    "\n",
    "# Invert the scaling and convert the property unit to Kcal/mol\n",
    "target_inter_pred = (target_inter_pred[idx] * band_gap_std + band_gap_mean) * 627"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c47a55",
   "metadata": {},
   "source": [
    "Parse generated molecules and sort out invalid samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34881f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepsmiles\n",
    "\n",
    "converter = deepsmiles.Converter(rings=True, branches=True)\n",
    "\n",
    "molecule_list = []\n",
    "labels = []\n",
    "\n",
    "for i, item in enumerate(deep_smi_inter_pred):\n",
    "    try:\n",
    "        smi = converter.decode(item)\n",
    "        mol = Chem.MolFromSmiles(smi, sanitize = False)\n",
    "        \n",
    "        if mol is not None:\n",
    "            molecule_list.append(mol)\n",
    "            p = target_inter_pred[i][0]\n",
    "            labels.append(f'{smi} - {p:.2f} kcal/mol')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "figure = Draw.MolsToGridImage(molecule_list, legends=labels, molsPerRow=4, subImgSize=(300, 300), returnPNG=False)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
